{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model      Train Score      Test Score\n",
      "-----      -----------      ----------\n",
      "OLS        0.873           0.8484\n",
      "Ridge      0.8729          0.8481\n",
      "Lasso      0.8722          0.847\n",
      "Gboost     0.9806       -> 0.9503\n",
      "KNN        0.8598          0.6977\n",
      "\n",
      "The best model is Gradient Boosting Regressor: 0.9503\n"
     ]
    }
   ],
   "source": [
    "# Student Name : Markus Proesch\n",
    "# Cohort       : 4\n",
    "\n",
    "################################################################################\n",
    "# Import Packages\n",
    "################################################################################\n",
    "\n",
    "# importing packages\n",
    "import pandas as pd # data science essentials\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # enhanced data visualization\n",
    "import statsmodels.formula.api as smf # explanatory model \n",
    "from sklearn.model_selection import train_test_split #train/test/split\n",
    "from sklearn.linear_model import LinearRegression #Linear Regression\n",
    "from sklearn.linear_model import Ridge #Ridge Regression\n",
    "from sklearn.linear_model import Lasso #Lasso Regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor #Gradient Boosting Regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # KNN for Regression\n",
    "from sklearn.preprocessing import StandardScaler # standard scaler\n",
    "\n",
    "################################################################################\n",
    "# Load Data\n",
    "################################################################################\n",
    "\n",
    "\n",
    "original_df  = pd.read_excel('Apprentice Chef Dataset.xlsx')\n",
    "\n",
    "# Named my dataset chef while working on it \n",
    "chef         = original_df\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Feature Engineering, Variable Selection and (optional) Dataset Standardization\n",
    "################################################################################\n",
    "\n",
    "# Explore the data and struckture + columns\n",
    "#chef.info()\n",
    "#chef.describe()\n",
    "\n",
    "# Exploring the original variables in the dataset\n",
    "#chef.columns\n",
    "\n",
    "# Found the missing values in the dataset but they weren't used in the analysis\n",
    "#fill = 'Unknown'\n",
    "#chef['FAMILY_NAME'] = chef['FAMILY_NAME'].fillna(fill)\n",
    "\n",
    "\n",
    "# Developed a new variable presenting the avg. price per meal per customer\n",
    "# which became very important for the model later\n",
    "chef['AVG_PRICE_PER_MEAL'] = chef['REVENUE']/chef['TOTAL_MEALS_ORDERED']\n",
    "\n",
    "\n",
    "# In order to make it as a loop I had to remove all non-numeric variables \n",
    "chef_numb = chef.drop(['NAME','FIRST_NAME',\n",
    "                       'FAMILY_NAME', 'EMAIL'],\n",
    "                        axis = 1)\n",
    "\n",
    "# For loop for presenting the frequency of all numeric variables\n",
    "#for col in chef_numb:\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    \n",
    "    #plt.hist(chef[col], bins = 100)\n",
    "    #xlabel = print(f'{col}')\n",
    "    #plt.show()\n",
    "\n",
    "    \n",
    "# Outliers thresholds determined based on the histograms and scatterplots\n",
    "total_meals_ord_hi   = 180\n",
    "total_meals_ord_lo   = 25\n",
    "unique_meals_pur_hi  = 10\n",
    "contact_w_custo_s_lo = 2\n",
    "contact_w_custo_s_hi = 10\n",
    "avg_time_per_site_hi = 210\n",
    "cancel_bef_noon_hi   = 4\n",
    "cancel_aft_noon_hi   = 2\n",
    "mobile_log_lo        = 4\n",
    "mobile_log_hi        = 7\n",
    "pc_log_hi            = 3\n",
    "weekly_plan_hi       = 15\n",
    "late_deliv_hi        = 5\n",
    "avg_prep_vid_time_hi = 220\n",
    "avg_prep_vid_time_lo = 65\n",
    "largest_order_hi     = 8\n",
    "master_class_hi      = 2\n",
    "avg_click_per_lo     = 7\n",
    "total_photo_hi       = 300\n",
    "avg_price_per_m_hi   = 50\n",
    "revenue_hi           = 2200\n",
    "\n",
    "\n",
    "## Developing threshold for outliers\n",
    "# REVENUE \n",
    "chef['out_REVENUE']  = 0\n",
    "condition_hi = chef.loc[0:,'out_REVENUE'][chef['REVENUE'] \n",
    "                                          > revenue_hi]\n",
    "\n",
    "chef['out_REVENUE'].replace(to_replace = condition_hi,\n",
    "                            value      = 1,\n",
    "                            inplace    = True)\n",
    "\n",
    "# TOTAL MEALS ORDERED\n",
    "chef['out_TOTAL_MEALS_ORDERED'] = 0\n",
    "condition_hi = chef.loc[0:,'out_TOTAL_MEALS_ORDERED'][chef['TOTAL_MEALS_ORDERED'] \n",
    "                                                      > total_meals_ord_hi]\n",
    "condition_lo = chef.loc[0:,'out_TOTAL_MEALS_ORDERED'][chef['TOTAL_MEALS_ORDERED'] \n",
    "                                                      > total_meals_ord_lo]\n",
    "\n",
    "chef['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_hi,\n",
    "                                        value      = 1,\n",
    "                                        inplace    = True)\n",
    "chef['out_TOTAL_MEALS_ORDERED'].replace(to_replace = condition_lo,\n",
    "                                        value      = 1,\n",
    "                                        inplace    = True)\n",
    "\n",
    "# UNIQUE MEALS \n",
    "chef['out_UNIQUE_MEALS_PURCH']  = 0\n",
    "condition_hi = chef.loc[0:,'out_UNIQUE_MEALS_PURCH'][chef['UNIQUE_MEALS_PURCH'] \n",
    "                                                     > unique_meals_pur_hi]\n",
    "\n",
    "chef['out_UNIQUE_MEALS_PURCH'].replace(to_replace = condition_hi,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "# CONTACTS_W_CUSTOMER_SERVICE\n",
    "chef['out_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = chef.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][chef['CONTACTS_W_CUSTOMER_SERVICE'] \n",
    "                                                              > contact_w_custo_s_hi]\n",
    "condition_lo = chef.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][chef['CONTACTS_W_CUSTOMER_SERVICE'] \n",
    "                                                              > contact_w_custo_s_lo]\n",
    "\n",
    "chef['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                                value      = 1,\n",
    "                                                inplace    = True)\n",
    "chef['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_lo,\n",
    "                                                value      = 1,\n",
    "                                                inplace    = True)\n",
    "\n",
    "# AVG TIME PER SITE VISIT\n",
    "chef['out_AVG_TIME_PER_SITE_VISIT']  = 0\n",
    "condition_hi = chef.loc[0:,'out_AVG_TIME_PER_SITE_VISIT'][chef['AVG_TIME_PER_SITE_VISIT'] \n",
    "                                                          > avg_time_per_site_hi]\n",
    "\n",
    "chef['out_AVG_TIME_PER_SITE_VISIT'].replace(to_replace = condition_hi,\n",
    "                                            value      = 1,\n",
    "                                            inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_BEFORE_NOON\n",
    "chef['out_CANCELLATIONS_BEFORE_NOON'] = 0\n",
    "condition_hi = chef.loc[0:,'out_CANCELLATIONS_BEFORE_NOON'][chef['CANCELLATIONS_BEFORE_NOON'] \n",
    "                                                            > cancel_bef_noon_hi]\n",
    "\n",
    "chef['out_CANCELLATIONS_BEFORE_NOON'].replace(to_replace = condition_hi,\n",
    "                                              value      = 1,\n",
    "                                              inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_AFTER_NOON\n",
    "chef['out_CANCELLATIONS_AFTER_NOON'] = 0\n",
    "condition_hi = chef.loc[0:,'out_CANCELLATIONS_AFTER_NOON'][chef['CANCELLATIONS_AFTER_NOON'] \n",
    "                                                           > cancel_aft_noon_hi]\n",
    "\n",
    "chef['out_CANCELLATIONS_AFTER_NOON'].replace(to_replace = condition_hi,\n",
    "                                             value      = 1,\n",
    "                                             inplace    = True)\n",
    "\n",
    "# MOBILE_LOGINS\n",
    "chef['out_MOBILE_LOGINS'] = 0\n",
    "condition_hi = chef.loc[0:,'out_MOBILE_LOGINS'][chef['MOBILE_LOGINS'] \n",
    "                                                > mobile_log_hi ]\n",
    "condition_lo = chef.loc[0:,'out_MOBILE_LOGINS'][chef['MOBILE_LOGINS'] \n",
    "                                                > mobile_log_lo ]\n",
    "\n",
    "chef['out_MOBILE_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                  value      = 1,\n",
    "                                  inplace    = True)\n",
    "chef['out_MOBILE_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                  value      = 1,\n",
    "                                  inplace    = True)\n",
    "\n",
    "# PC_LOGINS\n",
    "chef['out_PC_LOGINS'] = 0\n",
    "condition_hi = chef.loc[0:,'out_PC_LOGINS'][chef['PC_LOGINS'] \n",
    "                                            > pc_log_hi ]\n",
    "\n",
    "chef['out_PC_LOGINS'].replace(to_replace = condition_hi,\n",
    "                              value      = 1,\n",
    "                              inplace    = True)\n",
    "\n",
    "# WEEKLY_PLAN\n",
    "chef['out_WEEKLY_PLAN'] = 0\n",
    "condition_hi = chef.loc[0:,'out_WEEKLY_PLAN'][chef['WEEKLY_PLAN'] \n",
    "                                              > weekly_plan_hi]\n",
    "\n",
    "chef['out_WEEKLY_PLAN'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# LATE_DELIVERIES\n",
    "chef['out_LATE_DELIVERIES'] = 0\n",
    "condition_hi = chef.loc[0:,'out_LATE_DELIVERIES'][chef['LATE_DELIVERIES'] \n",
    "                                                  > late_deliv_hi]\n",
    "\n",
    "chef['out_LATE_DELIVERIES'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# AVG_PREP_VID_TIME\n",
    "chef['out_AVG_PREP_VID_TIME'] = 0\n",
    "condition_hi = chef.loc[0:,'out_AVG_PREP_VID_TIME'][chef['AVG_PREP_VID_TIME'] \n",
    "                                                    > avg_prep_vid_time_hi]\n",
    "condition_lo = chef.loc[0:,'out_AVG_PREP_VID_TIME'][chef['AVG_PREP_VID_TIME'] \n",
    "                                                    > avg_prep_vid_time_lo]\n",
    "\n",
    "chef['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_hi,\n",
    "                                      value      = 1,\n",
    "                                      inplace    = True)\n",
    "chef['out_AVG_PREP_VID_TIME'].replace(to_replace = condition_lo,\n",
    "                                      value      = 1,\n",
    "                                      inplace    = True)\n",
    "\n",
    "# LARGEST_ORDER_SIZE\n",
    "chef['out_LARGEST_ORDER_SIZE'] = 0\n",
    "condition_hi = chef.loc[0:,'out_LARGEST_ORDER_SIZE'][chef['LARGEST_ORDER_SIZE'] \n",
    "                                                     > largest_order_hi]\n",
    "\n",
    "chef['out_LARGEST_ORDER_SIZE'].replace(to_replace = condition_hi,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "# MASTER_CLASSES_ATTENDED\n",
    "chef['out_MASTER_CLASSES_ATTENDED'] = 0\n",
    "condition_hi = chef.loc[0:,'out_MASTER_CLASSES_ATTENDED'][chef['MASTER_CLASSES_ATTENDED'] \n",
    "                                                          > master_class_hi]\n",
    "\n",
    "chef['out_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,\n",
    "                                            value      = 1,\n",
    "                                            inplace    = True)\n",
    "\n",
    "# AVG_CLICKS_PER_VISIT\n",
    "chef['out_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_lo = chef.loc[0:,'out_AVG_CLICKS_PER_VISIT'][chef['AVG_CLICKS_PER_VISIT'] \n",
    "                                                       < avg_click_per_lo]\n",
    "\n",
    "chef['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_lo,\n",
    "                                         value      = 1,\n",
    "                                         inplace    = True)\n",
    "\n",
    "# TOTAL_PHOTOS_VIEWED\n",
    "chef['out_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition_hi = chef.loc[0:,'out_TOTAL_PHOTOS_VIEWED'][chef['TOTAL_PHOTOS_VIEWED'] \n",
    "                                                      > total_photo_hi]\n",
    "\n",
    "chef['out_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition_hi,\n",
    "                                        value      = 1,\n",
    "                                        inplace    = True)\n",
    "\n",
    "# AVG_PRICE_PER_MEAL\n",
    "chef['out_AVG_PRICE_PER_MEAL'] = 0\n",
    "condition_hi = chef.loc[0:,'out_AVG_PRICE_PER_MEAL'][chef['AVG_PRICE_PER_MEAL'] \n",
    "                                                     > avg_price_per_m_hi]\n",
    "\n",
    "chef['out_AVG_PRICE_PER_MEAL'].replace(to_replace = condition_hi,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "\n",
    "# for loop to plot scatterplots with y = REVENUE and x = all variables\n",
    "#for col in chef_numb:\n",
    "    \n",
    "    #fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    \n",
    "    #plt.scatter(x = chef_numb[col], y = 'REVENUE',\n",
    "                #data = chef_numb, alpha = 0.7)\n",
    "    #xlabel = print(f'{col}')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "# Developing zero inflation variables where 0 had a big impact\n",
    "total_photo_viewed_change_at = 0 # zero inflated\n",
    "weekly_plan_change_at        = 0 # zero inflated\n",
    "\n",
    "\n",
    "\n",
    "chef['change_TOTAL_PHOTOS_VIEWED'] = 0\n",
    "condition = chef.loc[0:,'change_TOTAL_PHOTOS_VIEWED'][chef['TOTAL_PHOTOS_VIEWED'] \n",
    "                                                      == total_photo_viewed_change_at]\n",
    "\n",
    "chef['change_TOTAL_PHOTOS_VIEWED'].replace(to_replace = condition,\n",
    "                                           value      = 1,\n",
    "                                           inplace    = True)\n",
    "\n",
    "chef['change_WEEKLY_PLAN'] = 0\n",
    "condition = chef.loc[0:,'change_WEEKLY_PLAN'][chef['WEEKLY_PLAN'] \n",
    "                                              == weekly_plan_change_at]\n",
    "\n",
    "chef['change_WEEKLY_PLAN'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "\n",
    "\n",
    "# Correlation chart with variables correlation with REVENUE\n",
    "# Correlation insight were key to find the 2 important insight\n",
    "chef_corr1 = chef.corr().round(2)\n",
    "\n",
    "# Heatmap gave a good overview over correlation within the dataset\n",
    "#fig, ax = plt.subplots(figsize  = (20,20))\n",
    "\n",
    "#sns.heatmap(chef_corr, cmap = 'coolwarm',\n",
    "#            square = True, annot = True,\n",
    "#            linecolor = 'black', linewidths = 0.5)\n",
    "\n",
    "# Looking at correlation with REVENUE\n",
    "#print(chef_corr1['REVENUE'].sort_values(ascending=False))\n",
    "\n",
    "# Finding correlation for MEDIAN_MEAL_RATING triggering the insight\n",
    "#print(chef_corr1['MEDIAN_MEAL_RATING'].sort_values(ascending=False))\n",
    "    \n",
    "    \n",
    "    \n",
    "# Model showing the relationship between median rating and avg click per visit\n",
    "# essential for the insight and recommendation\n",
    "#fig, ax = plt.subplots(figsize = (10, 8))\n",
    "\n",
    "#plt.scatter(x = 'AVG_CLICKS_PER_VISIT', y = 'MEDIAN_MEAL_RATING',\n",
    "                #data = chef_numb, alpha = 0.7)\n",
    "#plt.show()\n",
    "    \n",
    "    \n",
    "# Dummie variables from the email domain.\n",
    "# Dataset has to be a DataFrame for .iterrows() to work\n",
    "chef_email       = pd.DataFrame(chef['EMAIL'])\n",
    "\n",
    "placeholder_lst  = []\n",
    "\n",
    "for index, col in chef_email.iterrows():\n",
    "    split_email  = chef_email.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "email_df         = pd.DataFrame(placeholder_lst)\n",
    "email_df.columns = ['name', 'domain']\n",
    "\n",
    "# Domain groups\n",
    "personal_domain     = ['@gmail.com', '@yahoo.com','@protonmail.com']\n",
    "professional_domain = ['@mmm.com', '@amex.com','@apple.com',\n",
    "                      '@boeing.com','@caterpillar.com',\n",
    "                      '@chevron.com','@cisco.com','@cocacola.com',\n",
    "                      '@disney.com','@dupont.com','@exxon.com',\n",
    "                      '@ge.org','@goldmansacs.com','@homedepot.com',\n",
    "                      '@ibm.com','@intel.com','@jnj.com',\n",
    "                      '@jpmorgan.com','@mcdonalds.com','@merck.com',\n",
    "                      '@microsoft.com','@nike.com','@pfizer.com',\n",
    "                      '@pg.com','@travelers.com','@unitedtech.com',\n",
    "                      '@unitedhealth.com','@verizon.com','@visa.com',\n",
    "                      '@walmart.com']\n",
    "junk_domain         = ['@me.com', '@aol.com', '@hotmail.com', '@live.com',\n",
    "                       '@msn.com','@passport.com']\n",
    "\n",
    "# For loop categorising the different email domains\n",
    "placeholder_lst = []\n",
    "\n",
    "for domain in email_df['domain']:\n",
    "    \n",
    "    if '@' + domain in personal_domain:\n",
    "        placeholder_lst.append('personal')\n",
    "    elif '@' + domain in professional_domain:\n",
    "        placeholder_lst.append('professional')\n",
    "    else:\n",
    "        placeholder_lst.append('junk')\n",
    "        \n",
    "# make the columns into a series to append it to original dataset        \n",
    "email_df['DOMAIN_GROUP'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# Add the domain categories column to the original dataset \n",
    "chef['DOMAIN'] = email_df['DOMAIN_GROUP']\n",
    "\n",
    "# Get dummies from the domain variable and drop the original column\n",
    "one_hot_DOMAIN = pd.get_dummies(chef['DOMAIN'])\n",
    "\n",
    "# Remove the old and add the 3 new columns\n",
    "chef           = chef.drop('DOMAIN', axis = 1)\n",
    "chef           = chef.join([one_hot_DOMAIN])\n",
    "\n",
    "\n",
    "\n",
    "chef_numb = chef.drop(['REVENUE', 'NAME', 'EMAIL', \n",
    "                       'FIRST_NAME','FAMILY_NAME'], axis = 1)\n",
    "\n",
    "# For loop to print the numeric variable in the right format for Statmodel\n",
    "#for col in chef_numb:\n",
    "    #print(f\"chef['{col}'] +\")\n",
    "\n",
    "\n",
    "# The developed model after removing bacause of high p-values: \n",
    "\n",
    "## REMOVED VARIABLES: \n",
    "## CROSS_SELL_SUCCESS, UNIQUE_MEALS_PURCH, PRODUCT_CATEGORIES_VIEWED,\n",
    "## AVG_TIME_PER_SITE_VISIT, MOBILE_NUMBER, CANCELLATIONS_BEFORE_NOON,\n",
    "## CANCELLATIONS_AFTER_NOON, TASTES_AND_PREFERENCES, MOBILE_LOGINS,\n",
    "## PC_LOGINS, WEEKLY_PLAN, PACKAGE_LOCKER, REFRIGERATED_LOCKER,\n",
    "## out_CONTACTS_W_CUSTOMER_SERVICE, out_AVG_TIME_PER_SITE_VISIT,\n",
    "## out_CANCELLATIONS_BEFORE_NOON, out_CANCELLATIONS_AFTER_NOON,\n",
    "## out_MOBILE_LOGINS, out_PC_LOGINS, out_WEEKLY_PLAN, out_LATE_DELIVERIES,\n",
    "## out_LARGEST_ORDER_SIZE, out_MASTER_CLASSES_ATTENDED, \n",
    "## out_AVG_PRICE_PER_MEAL, change_TOTAL_PHOTOS_VIEWED, change_WEEKLY_PLAN\n",
    "\n",
    "# Developed the model with p-value threshold at 0.1\n",
    "lm_fitted_chef = smf.ols(formula = \"\"\"chef['REVENUE']~\n",
    "chef['TOTAL_MEALS_ORDERED'] +\n",
    "chef['CONTACTS_W_CUSTOMER_SERVICE'] +\n",
    "chef['EARLY_DELIVERIES'] +\n",
    "chef['LATE_DELIVERIES'] +\n",
    "chef['FOLLOWED_RECOMMENDATIONS_PCT'] +\n",
    "chef['AVG_PREP_VID_TIME'] +\n",
    "chef['LARGEST_ORDER_SIZE'] +\n",
    "chef['MASTER_CLASSES_ATTENDED'] +\n",
    "chef['MEDIAN_MEAL_RATING'] +\n",
    "chef['AVG_CLICKS_PER_VISIT'] +\n",
    "chef['TOTAL_PHOTOS_VIEWED'] +\n",
    "chef['AVG_PRICE_PER_MEAL'] +\n",
    "chef['out_REVENUE'] +\n",
    "chef['out_TOTAL_MEALS_ORDERED'] +\n",
    "chef['out_UNIQUE_MEALS_PURCH'] +\n",
    "chef['out_AVG_PREP_VID_TIME'] +\n",
    "chef['out_AVG_CLICKS_PER_VISIT'] +\n",
    "chef['out_TOTAL_PHOTOS_VIEWED'] +\n",
    "chef['out_AVG_PRICE_PER_MEAL'] +\n",
    "chef['junk'] +\n",
    "chef['personal'] +\n",
    "chef['professional']\"\"\", data = chef)\n",
    "\n",
    "result_fitted_chef = lm_fitted_chef.fit()\n",
    "\n",
    "result_fitted_chef.summary()\n",
    "\n",
    "\n",
    "# declaring set of x-variables\n",
    "x_variables = ['TOTAL_MEALS_ORDERED','CONTACTS_W_CUSTOMER_SERVICE',\n",
    "                'EARLY_DELIVERIES','LATE_DELIVERIES', 'AVG_PREP_VID_TIME',\n",
    "                'FOLLOWED_RECOMMENDATIONS_PCT','LARGEST_ORDER_SIZE',\n",
    "                'MASTER_CLASSES_ATTENDED', 'MEDIAN_MEAL_RATING',\n",
    "                'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED',\n",
    "                'AVG_PRICE_PER_MEAL' ,'out_REVENUE', 'out_TOTAL_MEALS_ORDERED', \n",
    "                'out_UNIQUE_MEALS_PURCH','out_AVG_PREP_VID_TIME', \n",
    "                'out_AVG_CLICKS_PER_VISIT', 'out_TOTAL_PHOTOS_VIEWED',\n",
    "                'out_AVG_PRICE_PER_MEAL','junk', 'personal', 'professional']\n",
    "\n",
    "# Assigning only REVENUE as target variable\n",
    "target_data      = chef.loc[ : , 'REVENUE']\n",
    "\n",
    "# All other variables are explanatory\n",
    "explanatory_data = chef.loc[ : , x_variables]\n",
    "\n",
    "\n",
    "# The data was standardized the dataset with StandardScaler() but it had no effect on \n",
    "# the final model so I decided not to include it to save space and time\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "#scaler.fit(chef_data)\n",
    "\n",
    "#X_scaled = scaler.transform(chef_data)\n",
    "\n",
    "#X_scaled_df = pd.DataFrame(X_scaled)\n",
    "\n",
    "# adding the column name back to the standardized dataframe\n",
    "#X_scaled_df.columns = chef_data.columns\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Train/Test Split\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# The code to divide dataset into a train set (75%) and test set (25%)\n",
    "# with the random seed number as 222\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            explanatory_data,\n",
    "            target_data,\n",
    "            test_size = 0.25,\n",
    "            random_state = 222)\n",
    "\n",
    "################################################################################\n",
    "# Final Model (instantiate, fit, and predict)\n",
    "################################################################################\n",
    "\n",
    "## Linear Regression \n",
    "lr      = LinearRegression()\n",
    "\n",
    "# FITTING the training data\n",
    "lr_fit  = lr.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "lr_pred = lr_fit.predict(X_test)\n",
    "\n",
    "# saving scoring data for table\n",
    "lr_train_score = lr.score(X_train, y_train).round(4)\n",
    "lr_test_score  = lr.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "## Ridge Regression\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# FITTING the training data\n",
    "ridge_fit   = ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "ridge_pred  = ridge_model.predict(X_test)\n",
    "\n",
    "# saving scoring data for table\n",
    "ridge_train_score = ridge_model.score(X_train, y_train).round(4)\n",
    "ridge_test_score  = ridge_model.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# FITTING the training data\n",
    "lasso_fit   = lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "lasso_pred  = lasso_model.predict(X_test)\n",
    "\n",
    "# saving scoring data for table\n",
    "lasso_train_score = lasso_model.score(X_train, y_train).round(4)\n",
    "lasso_test_score  = lasso_model.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "Gboost      = GradientBoostingRegressor(random_state = 123)\n",
    "\n",
    "# FITTING the training data\n",
    "Gboost_fit  = Gboost.fit(X_train, y_train)\n",
    "\n",
    "# PREDICTING on test data\n",
    "Gboost_pred = Gboost.predict(X_test)\n",
    "\n",
    "# saving scoring data for table\n",
    "Gboost_train_score = Gboost.score(X_train, y_train).round(4)\n",
    "Gboost_test_score  = Gboost.score(X_test, y_test).round(4)\n",
    "\n",
    "\n",
    "## Finding the best number of neighbors for KNN\n",
    "training_accuracy = []\n",
    "test_accuracy     = []\n",
    "\n",
    "\n",
    "# Trying n_neighbors between 1 and 50 to see which one gives the highest r^2\n",
    "neighbors_settings = range(1, 50)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # Building the model\n",
    "    clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Recording the training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "    # Recording the generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "opt_neighbors = test_accuracy.index(max(test_accuracy)) + 1\n",
    "\n",
    "\n",
    "## KNearestNeighbor Regression\n",
    "knn_reg = KNeighborsRegressor(algorithm = 'auto',\n",
    "                              n_neighbors = opt_neighbors)\n",
    "\n",
    "# FITTING to the training data\n",
    "knn_reg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on test data\n",
    "knn_reg_pred = knn_reg.predict(X_test)\n",
    "\n",
    "# saving scoring data for table\n",
    "knn_reg_score_train = knn_reg.score(X_train, y_train).round(4)\n",
    "knn_reg_score_test  = knn_reg.score(X_test, y_test).round(4)\n",
    "\n",
    "# Comparing table\n",
    "\n",
    "print(f\"\"\"\n",
    "Model      Train Score      Test Score\n",
    "-----      -----------      ----------\n",
    "OLS        {lr_train_score}           {lr_test_score}\n",
    "Ridge      {ridge_train_score}          {ridge_test_score}\n",
    "Lasso      {lasso_train_score}          {lasso_test_score}\n",
    "Gboost     {Gboost_train_score}       -> {Gboost_test_score}\n",
    "KNN        {knn_reg_score_train}          {knn_reg_score_test}\n",
    "\"\"\")\n",
    "\n",
    "print(f'The best model is Gradient Boosting Regressor: {Gboost_test_score}')\n",
    "################################################################################\n",
    "# Final Model Score (score)\n",
    "################################################################################\n",
    "\n",
    "# use this space to score your final model on the testing set\n",
    "# MAKE SURE TO SAVE YOUR TEST SCORE AS test_score\n",
    "# Example: test_score = final_model.score(X_test, y_test)\n",
    "\n",
    "test_score = Gboost.score(X_test, y_test).round(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
